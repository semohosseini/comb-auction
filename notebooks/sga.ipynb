{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submodular Gradient Ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comblearn.nn import DSF\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "mo = 50\n",
    "dsf = DSF(n, 1, mo, [3, 4, 3], 20).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([38.9064], device='cuda:0', grad_fn=<MinimumBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1]).float().to(device)\n",
    "dsf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.7051, 0.1668, 0.1185],\n",
       "        [1.4048, 0.6906, 0.9834],\n",
       "        [1.1202, 0.1517, 1.5553],\n",
       "        [0.2875, 0.4174, 1.1005],\n",
       "        [1.2695, 0.1578, 1.7497],\n",
       "        [1.6367, 0.4558, 0.4135],\n",
       "        [0.8231, 0.3081, 0.4602],\n",
       "        [1.0114, 0.3765, 0.2798],\n",
       "        [0.7217, 0.5841, 0.3563],\n",
       "        [1.2543, 1.6676, 0.3427]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dsf.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class DSFWrapper(nn.Module):\n",
    "    def __init__(self, n, dsf):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.zeros((n, ))).float()\n",
    "        self.submodular = dsf\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = (x > 0).float()\n",
    "        return self.submodular(mask * self.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "eps = 0.05\n",
    "T = int((n / eps) ** 2)\n",
    "lr = 2e-5\n",
    "\n",
    "wrapper = DSFWrapper(n, dsf).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.7051, 0.1668, 0.1185],\n",
       "         [1.4048, 0.6906, 0.9834],\n",
       "         [1.1202, 0.1517, 1.5553],\n",
       "         [0.2875, 0.4174, 1.1005],\n",
       "         [1.2695, 0.1578, 1.7497],\n",
       "         [1.6367, 0.4558, 0.4135],\n",
       "         [0.8231, 0.3081, 0.4602],\n",
       "         [1.0114, 0.3765, 0.2798],\n",
       "         [0.7217, 0.5841, 0.3563],\n",
       "         [1.2543, 1.6676, 0.3427]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[1.6228, 0.1074, 1.0731, 0.0495],\n",
       "         [1.0709, 0.6211, 0.8073, 0.2202],\n",
       "         [0.6275, 1.2969, 1.8320, 0.6924]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.2090, 0.4987, 0.7444],\n",
       "         [0.7260, 0.8825, 0.1297],\n",
       "         [0.2175, 0.3937, 0.6226],\n",
       "         [0.1695, 1.8481, 1.4049]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[3.3098],\n",
       "         [0.9882],\n",
       "         [0.0670]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.], device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(wrapper.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0/4000\n",
      "tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 4.4753, 17.2685, 18.6722, 12.8355, 20.9790, 11.9452,  8.6241,  8.0556,\n",
      "         8.6614, 15.7590], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([8.9505e-05, 3.4537e-04, 3.7344e-04, 2.5671e-04, 4.1958e-04, 2.3890e-04,\n",
      "        1.7248e-04, 1.6111e-04, 1.7323e-04, 3.1518e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Step 1/4000\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 8.9505, 34.5371, 37.3443, 25.6709, 41.9579, 23.8903, 17.2482, 16.1112,\n",
      "        17.3227, 31.5179], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0003, 0.0010, 0.0011, 0.0008, 0.0013, 0.0007, 0.0005, 0.0005, 0.0005,\n",
      "        0.0009], device='cuda:0', requires_grad=True)\n",
      "Step 2/4000\n",
      "tensor(0.1126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([13.4258, 51.8056, 56.0165, 38.5064, 62.9369, 35.8354, 25.8723, 24.1667,\n",
      "        25.9841, 47.2769], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0005, 0.0021, 0.0022, 0.0015, 0.0025, 0.0014, 0.0010, 0.0010, 0.0010,\n",
      "        0.0019], device='cuda:0', requires_grad=True)\n",
      "Step 3/4000\n",
      "tensor(0.2252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([17.9011, 69.0741, 74.6886, 51.3419, 83.9158, 47.7806, 34.4964, 32.2223,\n",
      "        34.6454, 63.0359], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0009, 0.0035, 0.0037, 0.0026, 0.0042, 0.0024, 0.0017, 0.0016, 0.0017,\n",
      "        0.0032], device='cuda:0', requires_grad=True)\n",
      "Step 4/4000\n",
      "tensor(0.3754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 22.3763,  86.3426,  93.3608,  64.1773, 104.8948,  59.7258,  43.1205,\n",
      "         40.2779,  43.3068,  78.7948], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0013, 0.0052, 0.0056, 0.0039, 0.0063, 0.0036, 0.0026, 0.0024, 0.0026,\n",
      "        0.0047], device='cuda:0', requires_grad=True)\n",
      "Step 5/4000\n",
      "tensor(0.5631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 26.8516, 103.6112, 112.0329,  77.0128, 125.8737,  71.6709,  51.7446,\n",
      "         48.3335,  51.9682,  94.5538], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0019, 0.0073, 0.0078, 0.0054, 0.0088, 0.0050, 0.0036, 0.0034, 0.0036,\n",
      "        0.0066], device='cuda:0', requires_grad=True)\n",
      "Step 6/4000\n",
      "tensor(0.7884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 31.3269, 120.8797, 130.7051,  89.8483, 146.8527,  83.6161,  60.3687,\n",
      "         56.3891,  60.6295, 110.3128], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0025, 0.0097, 0.0105, 0.0072, 0.0117, 0.0067, 0.0048, 0.0045, 0.0049,\n",
      "        0.0088], device='cuda:0', requires_grad=True)\n",
      "Step 7/4000\n",
      "tensor(1.0512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 35.8022, 138.1482, 149.3772, 102.6837, 167.8316,  95.5612,  68.9927,\n",
      "         64.4446,  69.2909, 126.0717], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0032, 0.0124, 0.0134, 0.0092, 0.0151, 0.0086, 0.0062, 0.0058, 0.0062,\n",
      "        0.0113], device='cuda:0', requires_grad=True)\n",
      "Step 8/4000\n",
      "tensor(1.3515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 40.2774, 155.4167, 168.0494, 115.5192, 188.8106, 107.5064,  77.6168,\n",
      "         72.5002,  77.9522, 141.8307], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0040, 0.0155, 0.0168, 0.0116, 0.0189, 0.0108, 0.0078, 0.0073, 0.0078,\n",
      "        0.0142], device='cuda:0', requires_grad=True)\n",
      "Step 9/4000\n",
      "tensor(1.6894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 44.7527, 172.6853, 186.7215, 128.3547, 209.7896, 119.4515,  86.2409,\n",
      "         80.5558,  86.6136, 157.5897], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0049, 0.0190, 0.0205, 0.0141, 0.0231, 0.0131, 0.0095, 0.0089, 0.0095,\n",
      "        0.0173], device='cuda:0', requires_grad=True)\n",
      "Step 10/4000\n",
      "tensor(2.0648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 49.2280, 189.9538, 205.3937, 141.1901, 230.7685, 131.3967,  94.8650,\n",
      "         88.6114,  95.2750, 173.3486], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0059, 0.0228, 0.0246, 0.0169, 0.0277, 0.0158, 0.0114, 0.0106, 0.0114,\n",
      "        0.0208], device='cuda:0', requires_grad=True)\n",
      "Step 11/4000\n",
      "tensor(2.4777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 53.7032, 207.2223, 224.0658, 154.0256, 251.7475, 143.3418, 103.4891,\n",
      "         96.6670, 103.9363, 189.1076], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0070, 0.0269, 0.0291, 0.0200, 0.0327, 0.0186, 0.0135, 0.0126, 0.0135,\n",
      "        0.0246], device='cuda:0', requires_grad=True)\n",
      "Step 12/4000\n",
      "tensor(2.9282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 58.1785, 224.4908, 242.7380, 166.8611, 272.7264, 155.2870, 112.1132,\n",
      "        104.7225, 112.5977, 204.8666], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0081, 0.0314, 0.0340, 0.0234, 0.0382, 0.0217, 0.0157, 0.0147, 0.0158,\n",
      "        0.0287], device='cuda:0', requires_grad=True)\n",
      "Step 13/4000\n",
      "tensor(3.4163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 62.6538, 241.7594, 261.4101, 179.6965, 293.7054, 167.2321, 120.7373,\n",
      "        112.7781, 121.2591, 220.6255], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0094, 0.0363, 0.0392, 0.0270, 0.0441, 0.0251, 0.0181, 0.0169, 0.0182,\n",
      "        0.0331], device='cuda:0', requires_grad=True)\n",
      "Step 14/4000\n",
      "tensor(3.9418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 67.1290, 259.0279, 280.0823, 192.5320, 314.6843, 179.1772, 129.3614,\n",
      "        120.8337, 129.9204, 236.3845], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0107, 0.0414, 0.0448, 0.0308, 0.0503, 0.0287, 0.0207, 0.0193, 0.0208,\n",
      "        0.0378], device='cuda:0', requires_grad=True)\n",
      "Step 15/4000\n",
      "tensor(4.5050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 71.6043, 276.2964, 298.7544, 205.3674, 335.6633, 191.1224, 137.9855,\n",
      "        128.8893, 138.5818, 252.1435], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0122, 0.0470, 0.0508, 0.0349, 0.0571, 0.0325, 0.0235, 0.0219, 0.0236,\n",
      "        0.0429], device='cuda:0', requires_grad=True)\n",
      "Step 16/4000\n",
      "tensor(5.1056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 76.0796, 293.5649, 317.4266, 218.2029, 356.6422, 203.0675, 146.6096,\n",
      "        136.9448, 147.2431, 267.9025], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0137, 0.0528, 0.0571, 0.0393, 0.0642, 0.0366, 0.0264, 0.0247, 0.0265,\n",
      "        0.0482], device='cuda:0', requires_grad=True)\n",
      "Step 17/4000\n",
      "tensor(5.7438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 80.5548, 310.8335, 336.0987, 231.0384, 377.6212, 215.0127, 155.2337,\n",
      "        145.0004, 155.9045, 283.6614], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0153, 0.0591, 0.0639, 0.0439, 0.0717, 0.0409, 0.0295, 0.0276, 0.0296,\n",
      "        0.0539], device='cuda:0', requires_grad=True)\n",
      "Step 18/4000\n",
      "tensor(6.4196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 85.0301, 328.1020, 354.7709, 243.8738, 398.6001, 226.9578, 163.8578,\n",
      "        153.0560, 164.5659, 299.4204], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0170, 0.0656, 0.0710, 0.0488, 0.0797, 0.0454, 0.0328, 0.0306, 0.0329,\n",
      "        0.0599], device='cuda:0', requires_grad=True)\n",
      "Step 19/4000\n",
      "tensor(7.1328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 89.5054, 345.3705, 373.4430, 256.7093, 419.5790, 238.9030, 172.4819,\n",
      "        161.1116, 173.2272, 315.1794], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0188, 0.0725, 0.0784, 0.0539, 0.0881, 0.0502, 0.0362, 0.0338, 0.0364,\n",
      "        0.0662], device='cuda:0', requires_grad=True)\n",
      "Step 20/4000\n",
      "tensor(7.8837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 93.9806, 362.6390, 392.1152, 269.5448, 440.5580, 250.8481, 181.1060,\n",
      "        169.1671, 181.8886, 330.9384], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0207, 0.0798, 0.0863, 0.0593, 0.0969, 0.0552, 0.0398, 0.0372, 0.0400,\n",
      "        0.0728], device='cuda:0', requires_grad=True)\n",
      "Step 21/4000\n",
      "tensor(8.6720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 98.4559, 379.9076, 410.7873, 282.3803, 461.5369, 262.7933, 189.7301,\n",
      "        177.2227, 190.5499, 346.6973], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0226, 0.0874, 0.0945, 0.0649, 0.1062, 0.0604, 0.0436, 0.0408, 0.0438,\n",
      "        0.0797], device='cuda:0', requires_grad=True)\n",
      "Step 22/4000\n",
      "tensor(9.4979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([102.9312, 397.1761, 429.4595, 295.2158, 482.5159, 274.7384, 198.3542,\n",
      "        185.2783, 199.2113, 362.4563], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0247, 0.0953, 0.1031, 0.0709, 0.1158, 0.0659, 0.0476, 0.0445, 0.0478,\n",
      "        0.0870], device='cuda:0', requires_grad=True)\n",
      "Step 23/4000\n",
      "tensor(10.3614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([107.4064, 414.4446, 448.1316, 308.0512, 503.4948, 286.6836, 206.9783,\n",
      "        193.3338, 207.8727, 378.2153], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0269, 0.1036, 0.1120, 0.0770, 0.1259, 0.0717, 0.0517, 0.0483, 0.0520,\n",
      "        0.0946], device='cuda:0', requires_grad=True)\n",
      "Step 24/4000\n",
      "tensor(11.2624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([111.8817, 431.7131, 466.8038, 320.8867, 524.4738, 298.6288, 215.6024,\n",
      "        201.3894, 216.5340, 393.9742], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0291, 0.1122, 0.1214, 0.0834, 0.1364, 0.0776, 0.0561, 0.0524, 0.0563,\n",
      "        0.1024], device='cuda:0', requires_grad=True)\n",
      "Step 25/4000\n",
      "tensor(12.2009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([116.3570, 448.9817, 485.4759, 333.7222, 545.4527, 310.5739, 224.2265,\n",
      "        209.4450, 225.1954, 409.7332], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0314, 0.1212, 0.1311, 0.0901, 0.1473, 0.0839, 0.0605, 0.0566, 0.0608,\n",
      "        0.1106], device='cuda:0', requires_grad=True)\n",
      "Step 26/4000\n",
      "tensor(13.1770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([120.8322, 466.2502, 504.1481, 346.5577, 566.4316, 322.5191, 232.8506,\n",
      "        217.5006, 233.8568, 425.4922], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0338, 0.1306, 0.1412, 0.0970, 0.1586, 0.0903, 0.0652, 0.0609, 0.0655,\n",
      "        0.1191], device='cuda:0', requires_grad=True)\n",
      "Step 27/4000\n",
      "tensor(14.1906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([125.3075, 483.5187, 522.8203, 359.3932, 587.4106, 334.4642, 241.4747,\n",
      "        225.5561, 242.5181, 441.2512], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0363, 0.1402, 0.1516, 0.1042, 0.1703, 0.0970, 0.0700, 0.0654, 0.0703,\n",
      "        0.1280], device='cuda:0', requires_grad=True)\n",
      "Step 28/4000\n",
      "tensor(15.2418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([129.7828, 500.7872, 541.4924, 372.2286, 608.3895, 346.4094, 250.0988,\n",
      "        233.6117, 251.1795, 457.0101], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0389, 0.1502, 0.1624, 0.1117, 0.1825, 0.1039, 0.0750, 0.0701, 0.0754,\n",
      "        0.1371], device='cuda:0', requires_grad=True)\n",
      "Step 29/4000\n",
      "tensor(16.3305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([134.2580, 518.0558, 560.1646, 385.0641, 629.3685, 358.3546, 258.7229,\n",
      "        241.6673, 259.8408, 472.7691], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0416, 0.1606, 0.1737, 0.1194, 0.1951, 0.1111, 0.0802, 0.0749, 0.0806,\n",
      "        0.1466], device='cuda:0', requires_grad=True)\n",
      "Step 30/4000\n",
      "tensor(17.4567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([138.7333, 535.3243, 578.8368, 397.8996, 650.3474, 370.2997, 267.3470,\n",
      "        249.7229, 268.5022, 488.5281], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0444, 0.1713, 0.1852, 0.1273, 0.2081, 0.1185, 0.0856, 0.0799, 0.0859,\n",
      "        0.1563], device='cuda:0', requires_grad=True)\n",
      "Step 31/4000\n",
      "tensor(18.6205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([143.2086, 552.5929, 597.5090, 410.7351, 671.3264, 382.2449, 275.9710,\n",
      "        257.7784, 277.1635, 504.2870], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0473, 0.1824, 0.1972, 0.1355, 0.2215, 0.1261, 0.0911, 0.0851, 0.0915,\n",
      "        0.1664], device='cuda:0', requires_grad=True)\n",
      "Step 32/4000\n",
      "tensor(19.8218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([147.6838, 569.8615, 616.1812, 423.5706, 692.3053, 394.1900, 284.5951,\n",
      "        265.8340, 285.8249, 520.0460], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0502, 0.1938, 0.2095, 0.1440, 0.2354, 0.1340, 0.0968, 0.0904, 0.0972,\n",
      "        0.1768], device='cuda:0', requires_grad=True)\n",
      "Step 33/4000\n",
      "tensor(21.0606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([152.1591, 587.1300, 634.8533, 436.4060, 713.2842, 406.1352, 293.2192,\n",
      "        273.8896, 294.4862, 535.8050], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0533, 0.2055, 0.2222, 0.1527, 0.2496, 0.1421, 0.1026, 0.0959, 0.1031,\n",
      "        0.1875], device='cuda:0', requires_grad=True)\n",
      "Step 34/4000\n",
      "tensor(22.3371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([156.6344, 604.3986, 653.5255, 449.2415, 734.2632, 418.0804, 301.8433,\n",
      "        281.9452, 303.1476, 551.5640], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0564, 0.2176, 0.2353, 0.1617, 0.2643, 0.1505, 0.1087, 0.1015, 0.1091,\n",
      "        0.1986], device='cuda:0', requires_grad=True)\n",
      "Step 35/4000\n",
      "tensor(23.6510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([161.1096, 621.6671, 672.1977, 462.0770, 755.2421, 430.0255, 310.4674,\n",
      "        290.0007, 311.8089, 567.3229], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0596, 0.2300, 0.2487, 0.1710, 0.2794, 0.1591, 0.1149, 0.1073, 0.1154,\n",
      "        0.2099], device='cuda:0', requires_grad=True)\n",
      "Step 36/4000\n",
      "tensor(25.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([165.5849, 638.9357, 690.8699, 474.9125, 776.2211, 441.9707, 319.0915,\n",
      "        298.0563, 320.4702, 583.0819], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0629, 0.2428, 0.2625, 0.1805, 0.2950, 0.1679, 0.1213, 0.1133, 0.1218,\n",
      "        0.2216], device='cuda:0', requires_grad=True)\n",
      "Step 37/4000\n",
      "tensor(26.3915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([170.0602, 656.2042, 709.5421, 487.7480, 797.2000, 453.9158, 327.7155,\n",
      "        306.1119, 329.1316, 598.8409], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0663, 0.2559, 0.2767, 0.1902, 0.3109, 0.1770, 0.1278, 0.1194, 0.1284,\n",
      "        0.2335], device='cuda:0', requires_grad=True)\n",
      "Step 38/4000\n",
      "tensor(27.8181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([174.5354, 673.4728, 728.2142, 500.5834, 818.1790, 465.8610, 336.3396,\n",
      "        314.1674, 337.7929, 614.5999], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0698, 0.2694, 0.2913, 0.2002, 0.3273, 0.1863, 0.1345, 0.1257, 0.1351,\n",
      "        0.2458], device='cuda:0', requires_grad=True)\n",
      "Step 39/4000\n",
      "tensor(29.2822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([179.0107, 690.7413, 746.8864, 513.4189, 839.1579, 477.8062, 344.9637,\n",
      "        322.2230, 346.4543, 630.3588], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0734, 0.2832, 0.3062, 0.2105, 0.3441, 0.1959, 0.1414, 0.1321, 0.1420,\n",
      "        0.2584], device='cuda:0', requires_grad=True)\n",
      "Step 40/4000\n",
      "tensor(30.7838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([183.4859, 708.0099, 765.5586, 526.2543, 860.1368, 489.7513, 353.5878,\n",
      "        330.2786, 355.1156, 646.1178], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0771, 0.2974, 0.3215, 0.2210, 0.3613, 0.2057, 0.1485, 0.1387, 0.1491,\n",
      "        0.2714], device='cuda:0', requires_grad=True)\n",
      "Step 41/4000\n",
      "tensor(32.3230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([187.9612, 725.2784, 784.2308, 539.0898, 881.1158, 501.6965, 362.2119,\n",
      "        338.3342, 363.7770, 661.8768], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0808, 0.3119, 0.3372, 0.2318, 0.3789, 0.2157, 0.1558, 0.1455, 0.1564,\n",
      "        0.2846], device='cuda:0', requires_grad=True)\n",
      "Step 42/4000\n",
      "tensor(33.8998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([192.4365, 742.5470, 802.9030, 551.9252, 902.0947, 513.6416, 370.8360,\n",
      "        346.3897, 372.4383, 677.6357], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0847, 0.3267, 0.3533, 0.2428, 0.3969, 0.2260, 0.1632, 0.1524, 0.1639,\n",
      "        0.2982], device='cuda:0', requires_grad=True)\n",
      "Step 43/4000\n",
      "tensor(35.5140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([196.9117, 759.8156, 821.5751, 564.7607, 923.0737, 525.5867, 379.4601,\n",
      "        354.4453, 381.0997, 693.3947], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0886, 0.3419, 0.3697, 0.2541, 0.4154, 0.2365, 0.1708, 0.1595, 0.1715,\n",
      "        0.3120], device='cuda:0', requires_grad=True)\n",
      "Step 44/4000\n",
      "tensor(37.1659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([201.3870, 777.0841, 840.2473, 577.5961, 944.0526, 537.5319, 388.0841,\n",
      "        362.5009, 389.7610, 709.1537], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0926, 0.3575, 0.3865, 0.2657, 0.4343, 0.2473, 0.1785, 0.1668, 0.1793,\n",
      "        0.3262], device='cuda:0', requires_grad=True)\n",
      "Step 45/4000\n",
      "tensor(38.8552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([205.8623, 794.3527, 858.9195, 590.4316, 965.0316, 549.4770, 396.7082,\n",
      "        370.5565, 398.4224, 724.9127], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.0968, 0.3733, 0.4037, 0.2775, 0.4536, 0.2583, 0.1865, 0.1742, 0.1873,\n",
      "        0.3407], device='cuda:0', requires_grad=True)\n",
      "Step 46/4000\n",
      "tensor(40.5821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([210.3375, 811.6212, 877.5917, 603.2670, 986.0105, 561.4221, 405.3323,\n",
      "        378.6120, 407.0837, 740.6716], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.1010, 0.3896, 0.4212, 0.2896, 0.4733, 0.2695, 0.1946, 0.1817, 0.1954,\n",
      "        0.3555], device='cuda:0', requires_grad=True)\n",
      "Step 47/4000\n",
      "tensor(42.3466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 214.8128,  828.8898,  896.2639,  616.1025, 1006.9894,  573.3672,\n",
      "         413.9564,  386.6676,  415.7451,  756.4306], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.1053, 0.4062, 0.4392, 0.3019, 0.4934, 0.2809, 0.2028, 0.1895, 0.2037,\n",
      "        0.3707], device='cuda:0', requires_grad=True)\n",
      "Step 48/4000\n",
      "tensor(44.1485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 219.2881,  846.1583,  914.9360,  628.9379, 1027.9684,  585.3124,\n",
      "         422.5805,  394.7232,  424.4064,  772.1896], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.1096, 0.4231, 0.4575, 0.3145, 0.5140, 0.2927, 0.2113, 0.1974, 0.2122,\n",
      "        0.3861], device='cuda:0', requires_grad=True)\n",
      "Step 49/4000\n",
      "tensor(45.9881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 223.7633,  863.4269,  933.6082,  641.7734, 1048.9474,  597.2575,\n",
      "         431.2046,  402.7787,  433.0677,  787.9485], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.1141, 0.4403, 0.4761, 0.3273, 0.5350, 0.3046, 0.2199, 0.2054, 0.2209,\n",
      "        0.4019], device='cuda:0', requires_grad=True)\n",
      "Step 50/4000\n",
      "tensor(47.8651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 228.2386,  880.6954,  952.2804,  654.6088, 1069.9264,  609.2026,\n",
      "         439.8286,  410.8343,  441.7291,  803.7075], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.1187, 0.4580, 0.4952, 0.3404, 0.5564, 0.3168, 0.2287, 0.2136, 0.2297,\n",
      "        0.4179], device='cuda:0', requires_grad=True)\n",
      "Step 51/4000\n",
      "tensor(49.7797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 232.7139,  897.9640,  970.9526,  667.4443, 1090.9054,  621.1478,\n",
      "         448.4527,  418.8899,  450.3904,  819.4665], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.1233, 0.4759, 0.5146, 0.3537, 0.5782, 0.3292, 0.2377, 0.2220, 0.2387,\n",
      "        0.4343], device='cuda:0', requires_grad=True)\n",
      "Step 52/4000\n",
      "tensor(50., device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "G: tensor([ 232.7139,  897.9640,  970.9526,  667.4443, 1090.9054,  621.1478,\n",
      "         448.4527,  418.8899,  450.3904,  819.4665], device='cuda:0')\n",
      "W: Parameter containing:\n",
      "tensor([0.1280, 0.4939, 0.5340, 0.3671, 0.6000, 0.3416, 0.2466, 0.2304, 0.2477,\n",
      "        0.4507], device='cuda:0', requires_grad=True)\n",
      "Step 53/4000\n",
      "tensor(50., device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "last_pred = -1.0\n",
    "\n",
    "for i in range(T // batch_size):\n",
    "    print(f\"Step {i}/{T // batch_size}\")\n",
    "    \n",
    "    m = torch.ones((batch_size, n)).float().to(device)\n",
    "    pred = wrapper(m).mean()\n",
    "    print(pred)\n",
    "    pred.backward()\n",
    "    g = wrapper.weights.grad\n",
    "    \n",
    "    if pred == last_pred:\n",
    "        break\n",
    "    else:\n",
    "        last_pred = pred\n",
    "\n",
    "    print('G:', g)\n",
    "    with torch.no_grad():\n",
    "        wrapper.weights.add_(lr * g)\n",
    "        wrapper.weights.abs_()\n",
    "\n",
    "\n",
    "    print('W:', list(wrapper.parameters())[0])\n",
    "    # print('P:', list(dsf.parameters())[0][0])\n",
    "    \n",
    "# dsf.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1280, 0.4939, 0.5340, 0.3671, 0.6000, 0.3416, 0.2466, 0.2304, 0.2477,\n",
       "        0.4507], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.weights.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros((3, 4)).to(device)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0.],\n",
       "        [0., 0., 2., 0.],\n",
       "        [0., 0., 3., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:, 2] = torch.tensor([1, 2, 3])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.optim.sgd.SGD"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(\"torch.optim.SGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mohammad_hosseini/auction/notebooks\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "with open(\"../config/config_rg.yaml\") as fp:\n",
    "    cfg = yaml.load(fp, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auction': {'bidders': {'list': [0, 1, 2, 3, 4],\n",
       "   'value-function': [{'cls': 'comblearn.data.DSFValueFunction',\n",
       "     'max-out': 100,\n",
       "     'hidden-sizes': [2, 3, 2],\n",
       "     'alpha': 500}]},\n",
       "  'items': [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "  'q-init': 500,\n",
       "  'q-max': 510,\n",
       "  'device': 'cuda',\n",
       "  'marginal': False},\n",
       " 'dsf-learner': {'optimizer': 'torch.optim.SGD',\n",
       "  'learning-rate': 0.001,\n",
       "  'epochs': 1000,\n",
       "  'device': 'cuda'}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'items' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcomblearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DSFValueFunction\n\u001b[0;32m----> 3\u001b[0m \u001b[39meval\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mDSFValueFunction(items, 100, [2, 3, 2], 500)\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'items' is not defined"
     ]
    }
   ],
   "source": [
    "from comblearn.data import DSFValueFunction\n",
    "\n",
    "eval('DSFValueFunction(items, 100, [2, 3, 2], 500)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensordict.tensordict import TensorDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "batch dimension mismatch, got self.batch_size=torch.Size([1]) and value.shape[:self.batch_dims]=torch.Size([3]) with value tensor([1, 2, 3])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t \u001b[39m=\u001b[39m TensorDict({\u001b[39m'\u001b[39;49m\u001b[39mA\u001b[39;49m\u001b[39m'\u001b[39;49m: torch\u001b[39m.\u001b[39;49mtensor([\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m3\u001b[39;49m]), \u001b[39m'\u001b[39;49m\u001b[39mB\u001b[39;49m\u001b[39m'\u001b[39;49m: torch\u001b[39m.\u001b[39;49mtensor([\u001b[39m4\u001b[39;49m, \u001b[39m5\u001b[39;49m, \u001b[39m6\u001b[39;49m])}, batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/auction/lib/python3.10/site-packages/tensordict/tensordict.py:3399\u001b[0m, in \u001b[0;36mTensorDict.__init__\u001b[0;34m(self, source, batch_size, device, names, _run_checks, _is_shared, _is_memmap)\u001b[0m\n\u001b[1;32m   3397\u001b[0m \u001b[39mif\u001b[39;00m source \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3398\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m source\u001b[39m.\u001b[39mitems():\n\u001b[0;32m-> 3399\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset(key, value)\n",
      "File \u001b[0;32m~/anaconda3/envs/auction/lib/python3.10/site-packages/tensordict/tensordict.py:3689\u001b[0m, in \u001b[0;36mTensorDict.set\u001b[0;34m(self, key, value, inplace)\u001b[0m\n\u001b[1;32m   3686\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_locked \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m inplace:\n\u001b[1;32m   3687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(TensorDictBase\u001b[39m.\u001b[39mLOCK_ERROR)\n\u001b[0;32m-> 3689\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_value(value)\n\u001b[1;32m   3690\u001b[0m \u001b[39m# not calling set_ to avoid re-validate key\u001b[39;00m\n\u001b[1;32m   3691\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set(key, value, inplace\u001b[39m=\u001b[39minplace)\n",
      "File \u001b[0;32m~/anaconda3/envs/auction/lib/python3.10/site-packages/tensordict/tensordict.py:1554\u001b[0m, in \u001b[0;36mTensorDictBase._validate_value\u001b[0;34m(self, value, check_shape)\u001b[0m\n\u001b[1;32m   1552\u001b[0m         value\u001b[39m.\u001b[39mbatch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\n\u001b[1;32m   1553\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1554\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1555\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch dimension mismatch, got self.batch_size\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1556\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\u001b[39m}\u001b[39;00m\u001b[39m and value.shape[:self.batch_dims]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1557\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00m_shape(value)[:\u001b[39m \u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_dims]\u001b[39m}\u001b[39;00m\u001b[39m with value \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1558\u001b[0m         )\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1560\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_names \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1561\u001b[0m     \u001b[39mand\u001b[39;00m is_tensor_collection(value)\n\u001b[1;32m   1562\u001b[0m     \u001b[39mand\u001b[39;00m check_shape\n\u001b[1;32m   1563\u001b[0m     \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mnames[: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim] \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames\n\u001b[1;32m   1564\u001b[0m ):\n\u001b[1;32m   1565\u001b[0m     value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mclone(\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mrefine_names(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: batch dimension mismatch, got self.batch_size=torch.Size([1]) and value.shape[:self.batch_dims]=torch.Size([3]) with value tensor([1, 2, 3])"
     ]
    }
   ],
   "source": [
    "t = TensorDict({'A': torch.tensor([1, 2, 3]), 'B': torch.tensor([4, 5, 6])}, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{b: i for b, i in zip(range(3), range(3))}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
