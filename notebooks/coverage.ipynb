{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "1. First create your python environment using Anaconda or Virtualenv with `python>=3.10`.\n",
    "2. Install prerequisites: `pip install torch numpy matplotlib PyYAML`.\n",
    "3. Install auxilary package \"comblearn\" on the project root: `python setup.py develop`.\n",
    "4. Run \"Initialization\" part of the notebook.\n",
    "5. For the first experiment (Learning Coverage Function) run Part 1 of the notebook.\n",
    "6. For the second experiment (Maximizing Social Welfare) run Part 2 of the notebook.\n",
    "7. For each experiment use the trial config to generate desired output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "\n",
    "from comblearn.env import CombinatorialAuction\n",
    "\n",
    "logging.basicConfig(level=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf_configs = ['edsf', 'dsf', 'dpst', 'strf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Learning Coverage and Cut Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different configs to get the desired ouputs\n",
    "\n",
    "config = {\n",
    "    'prob': 'low', # ['low', 'mid', 'high'],\n",
    "    'function': 'edsf', # ['dsf', 'edsf', 'egdsf', 'dpst', 'strf']\n",
    "    'true': 'coverage' # ['coverage', 'cut']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml \n",
    "\n",
    "if config['true'] == 'coverage':\n",
    "    with open(\"config_coverage.yaml\") as fp:\n",
    "        cfg = yaml.load(fp, Loader=yaml.FullLoader)\n",
    "else:\n",
    "    with open(\"config_cut.yaml\") as fp:\n",
    "        cfg = yaml.load(fp, Loader=yaml.FullLoader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction = CombinatorialAuction(cfg['auction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['prob'] == 'low':\n",
    "    X, y = auction.data_handler.R['0']\n",
    "    vfa = auction.bidders[0].vf\n",
    "elif config['prob'] == 'mid':\n",
    "    X, y = auction.data_handler.R['1']\n",
    "    vfa = auction.bidders[1].vf\n",
    "else:\n",
    "    X, y = auction.data_handler.R['2']\n",
    "    vfa = auction.bidders[2].vf\n",
    "items = auction.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X.shape[0]\n",
    "tr = int(80/100 * n)\n",
    "X_train = X[0: tr]\n",
    "y_train = y[0: tr] \n",
    "X_test = X[tr:]\n",
    "y_test = y[tr:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comblearn.data import ExtendedDSFValueFunction, ExtendedGeneralDSFValueFunction\n",
    "from comblearn.data import DSFValueFunction, DeepSets, SetTransformer\n",
    "\n",
    "if config['function'] == 'edsf':\n",
    "    vf = ExtendedDSFValueFunction(items, 60, [64, 64, 64, 64], 95).to(\"cuda\")\n",
    "elif config['function'] == 'egdsf':\n",
    "    vf = ExtendedGeneralDSFValueFunction(items, 60, [64, 64, 64, 64, 10], 95).to(\"cuda\")\n",
    "elif config['function'] == 'dpst':\n",
    "    vf = DeepSets(items, [64, 64, 64], [64, 64, 64]).to('cuda')\n",
    "elif config['function'] == 'strf':\n",
    "    vf = SetTransformer(items, 1, 1, dim_hidden=128).to(\"cuda\")\n",
    "else:\n",
    "    vf = DSFValueFunction(items, 60, [64, 64, 64], 95).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "optimizer = Adam(vf.parameters(), lr=0.01)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "losses = []\n",
    "\n",
    "for _ in range(4000):\n",
    "    optimizer.zero_grad()\n",
    "    yp = vf(X_train)\n",
    "    loss = criterion(yp, y_train)\n",
    "    loss.backward(retain_graph=True)\n",
    "    losses.append(loss.item())\n",
    "    optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        vf.relu()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To chek the loss on test set\n",
    "\n",
    "yp = vf(X_test)\n",
    "criterion(yp, y_test).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot the loss throughout the iterations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(len(losses))\n",
    "plt.figure(figsize=(25, 20))\n",
    "plt.title('Loss Function', fontdict={'size': 50})\n",
    "plt.xlabel('iteration number', fontdict={'size': 42})\n",
    "plt.ylabel('loss', fontdict={'size': 42})\n",
    "plt.yticks(np.arange(min(losses), max(losses), (max(losses) - min(losses))//10 + 1), fontsize=30)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.plot(x, losses, label='coverage_function', color='black')\n",
    "plt.savefig(\"loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot the value of some of the training data after training and compare them to the real values\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(X_train[0: 50].shape[0])\n",
    "y1 = vf(X_train[0: 50]).squeeze().tolist()\n",
    "y2 = y_train[0: 50].squeeze().tolist()\n",
    "\n",
    "plt.figure(figsize=(25, 15))\n",
    "\n",
    "plt.title('True vs Predicted Value', fontdict={'size': 40})\n",
    "plt.xlabel('Train Samples', fontdict={'size': 30})\n",
    "plt.ylabel('Value of Train Samples', fontdict={'size': 30})\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.plot(x, y1, 'o--', label = \"predict\")\n",
    "plt.plot(x, y2, '^--', label = \"truth\")\n",
    "plt.legend(loc='lower left', fontsize=27)\n",
    "plt.savefig(\"train.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot the value of some of the test data after training and compare them to the real values\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(X_test[0: 50].shape[0])\n",
    "y1 = vf(X_test[0: 50]).squeeze().tolist()\n",
    "y2 = y_test[0: 50].tolist()\n",
    "print(vf(X_test[0: 50]).size())\n",
    "\n",
    "plt.figure(figsize=(25, 15))\n",
    "\n",
    "plt.title('True vs Predicted Value', fontdict={'size': 40})\n",
    "plt.xlabel('Test Samples', fontdict={'size': 30})\n",
    "plt.ylabel('Value of Test Samples', fontdict={'size': 30})\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.plot(x, y1, 'o--', label = \"predict\")\n",
    "plt.plot(x, y2, '^--', label = \"truth\")\n",
    "plt.legend(loc='lower left', fontsize=27)\n",
    "plt.savefig(\"test.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comblearn.data import ExtendedDSFValueFunction, DSFValueFunction, DeepSets, SetTransformer\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "\n",
    "def trial(no, tr_losses):\n",
    "    print(f\"Trial {no}:\")\n",
    "\n",
    "    auction = CombinatorialAuction(cfg['auction'])\n",
    "    if config['prob'] == 'low':\n",
    "        X, y = auction.data_handler.R['0']\n",
    "    elif config['prob'] == 'mid':\n",
    "        X, y = auction.data_handler.R['1']\n",
    "    else:\n",
    "        X, y = auction.data_handler.R['2']\n",
    "    items = auction.items\n",
    "\n",
    "    n = X.shape[0]\n",
    "    tr = int(80/100 * n)\n",
    "    X_train = X[0: tr]\n",
    "    y_train = y[0: tr] \n",
    "    X_test = X[tr:]\n",
    "    y_test = y[tr:]\n",
    "\n",
    "    for vfc in vf_configs:\n",
    "        print(f'Config {vfc}:')\n",
    "        if vfc == 'edsf':\n",
    "            vf = ExtendedDSFValueFunction(items, 60, [64, 64, 64, 64], 95).to(\"cuda\")\n",
    "        elif vfc == 'dpst':\n",
    "            vf = DeepSets(items, [512, 512, 512, 512], [512, 512, 512, 512]).to('cuda')\n",
    "        elif vfc == 'dsf':\n",
    "            vf = DSFValueFunction(items, 60, [64, 64, 64], 95).to(\"cuda\")\n",
    "        elif vfc == 'strf':\n",
    "            vf = SetTransformer(items, num_outputs=1, dim_output=1, dim_hidden=64).to(\"cuda\")\n",
    "\n",
    "        optimizer = Adam(vf.parameters(), lr=0.01)\n",
    "        criterion = nn.L1Loss()\n",
    "\n",
    "        losses = []\n",
    "\n",
    "        for _ in range(5000):\n",
    "            optimizer.zero_grad()\n",
    "            yp = vf(X_train)\n",
    "            loss = criterion(yp, y_train)\n",
    "            loss.backward(retain_graph=True)\n",
    "            losses.append(loss.item())\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                vf.relu()\n",
    "            if _ % 1000 == 0:\n",
    "                print(loss)\n",
    "        train_loss = loss\n",
    "\n",
    "        yp = vf(X_test)\n",
    "        test_loss = criterion(yp, y_test)\n",
    "\n",
    "        print(f'Train, Test loss: {[train_loss.item(), test_loss.item()]}')\n",
    "        tr_losses[vfc].append([train_loss.item(), test_loss.item()])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_losses = {'edsf': [], 'dsf': [], 'dpst': [], 'strf': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Maximizing Social Welfare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'function': 'edsf' # ['dsf', 'edsf', 'vnn', 'comp', 'comp_dsf']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml \n",
    "\n",
    "if config['function'] == 'edsf':\n",
    "    with open(\"config_edsf_social_welfare.yaml\") as fp:\n",
    "        cfg = yaml.load(fp, Loader=yaml.FullLoader)\n",
    "elif config['function'] == 'vnn':\n",
    "    with open(\"config_vnn_social_welfare.yaml\") as fp:\n",
    "        cfg = yaml.load(fp, Loader=yaml.FullLoader)\n",
    "elif config['function'] == 'comp':\n",
    "    with open(\"config_comp_social_welfare.yaml\") as fp:\n",
    "        cfg = yaml.load(fp, Loader=yaml.FullLoader)\n",
    "elif config['function'] == 'comp_dsf':\n",
    "    with open(\"config_dsf_comp_social_welfare.yaml\") as fp:\n",
    "        cfg = yaml.load(fp, Loader=yaml.FullLoader)\n",
    "else: \n",
    "    with open(\"config_dsf_social_welfare.yaml\") as fp:\n",
    "        cfg = yaml.load(fp, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "def social_welfare(ws, allocation):\n",
    "    return torch.sum(torch.tensor([w(alloc) for w, alloc in zip(ws, allocation)]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction = CombinatorialAuction(cfg['auction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocation, social_welfare = auction.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_welfare, allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction.allocation_config['scheme'] = 'GradientAscent'\n",
    "auction.allocation_config['optimizer'] = 'comblearn.optim.GradientAscentOptimizer'  # Change this to batch if you want to perform a batch optimization\n",
    "auction.allocation_config['learning-rate'] = 0.001\n",
    "auction.allocation_config['batch-size'] = 100\n",
    "auction.allocation_config['eps'] = 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocation, social_welfare, allocation1, social_welfare1 = auction.run()\n",
    "allocation, social_welfare = auction.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocation, social_welfare #, allocation1, social_welfare1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'optimal social welfare for auction with coverage value funciton is: {social_welfare}')\n",
    "print(f'final allocation for auction with coverage value functions is: {allocation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with Randomized Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "output = []\n",
    "for i in range(3):\n",
    "    auction = CombinatorialAuction(cfg['auction'])\n",
    "    optimal_social_welfare = auction.data_handler.opt_sw\n",
    "\n",
    "    auction.allocation_config['scheme'] = 'RandGreedy'\n",
    "    auction.allocation_config['optimizer'] = 'comblearn.optim.RandGreedyOptimizer'  # Change this to batch if you want to perform a batch optimization\n",
    "    auction.allocation_config['delta'] = 0.01\n",
    "    auction.allocation_config['batch-size'] = 100\n",
    "    auction.allocation_config['sample_rate'] = 5\n",
    "    s_rg = time()\n",
    "    _, rg_sw = auction.run()\n",
    "    e_rg = time()\n",
    "    auction.allocation_config['scheme'] = 'GradientAscent'\n",
    "    auction.allocation_config['optimizer'] = 'comblearn.optim.GradientAscentOptimizer'  # Change this to batch if you want to perform a batch optimization\n",
    "    auction.allocation_config['learning-rate'] = 0.001\n",
    "    auction.allocation_config['batch-size'] = 100\n",
    "    auction.allocation_config['eps'] = 0.00\n",
    "    s_ga = time()\n",
    "    _, ga_sw = auction.run()\n",
    "    e_ga = time()\n",
    "\n",
    "    output.append((rg_sw, ga_sw, e_rg - s_rg, e_ga - s_ga, optimal_social_welfare))\n",
    "\n",
    "    print('A:', (rg_sw, ga_sw, e_rg - s_rg, e_ga - s_ga, optimal_social_welfare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os = [[a.item(), b.item(), c, d] for a, b, c, d, _ in output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array(os)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.mean(axis=0), a.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Gradient Ascent with Optimal Social Welfare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comblearn.env import BruteForceOptimizer\n",
    "\n",
    "output = []\n",
    "for i in range(10):\n",
    "    auction = CombinatorialAuction(cfg['auction'])\n",
    "    optimal_social_welfare = auction.data_handler.opt_sw\n",
    "    # _, rg_social_welfare = auction.run()\n",
    "    auction.allocation_config['scheme'] = 'GradientAscent'\n",
    "    auction.allocation_config['optimizer'] = 'comblearn.optim.GradientAscentOptimizer'  # Change this to batch if you want to perform a batch optimization\n",
    "    auction.allocation_config['learning-rate'] = 0.001\n",
    "    auction.allocation_config['batch-size'] = 100\n",
    "    auction.allocation_config['eps'] = 0.00\n",
    "    _, sw, _,  sw1 = auction.run()\n",
    "\n",
    "    ws = [b.vf for b in auction.bidders]\n",
    "\n",
    "    edsf_learned = [vf for _, vf in auction.learning_handler.models.items()]\n",
    "    dsf_learned = [vf for _, vf in auction.learning_handler1.models.items()]\n",
    "    \n",
    "    optim_aux = BruteForceOptimizer(len(auction.items), len(auction.bidders), edsf_learned)\n",
    "    opt_alloc = optim_aux.optimize()\n",
    "    opt_learn_edsf_sw = social_welfare(ws, opt_alloc)\n",
    "\n",
    "    optim_aux = BruteForceOptimizer(len(auction.items), len(auction.bidders), dsf_learned)\n",
    "    opt_alloc = optim_aux.optimize()\n",
    "    opt_learn_dsf_sw = social_welfare(ws, opt_alloc)\n",
    "\n",
    "    output.append((sw, sw1, opt_learn_edsf_sw, opt_learn_dsf_sw, optimal_social_welfare))\n",
    "\n",
    "    print('A:', (sw, sw1, opt_learn_edsf_sw, opt_learn_dsf_sw, optimal_social_welfare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os = [[a.item(), b.item(), c.item(), d.item(), e.item()] for a, b, c, d, e in output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(os)\n",
    "np.mean(a, axis=0), np.std(a, axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
